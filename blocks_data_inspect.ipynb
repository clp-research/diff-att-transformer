{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VAL_IMAGES_BEFORE_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.hdf5',\n",
       " 'TRAIN_IMAGES_AFTER_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.hdf5',\n",
       " 'TEST_IMAGES_AFTER_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.hdf5',\n",
       " 'TEST_IMAGES_BEFORE_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.hdf5',\n",
       " 'TRAIN_CAPTIONS_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.json',\n",
       " 'TEST_CAPTIONS_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.json',\n",
       " 'VAL_CAPTIONS_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.json',\n",
       " 'TEST_CAPLENS_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.json',\n",
       " 'TRAIN_IMAGES_BEFORE_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.hdf5',\n",
       " '.ipynb_checkpoints',\n",
       " 'TRAIN_CAPLENS_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.json',\n",
       " 'WORDMAP_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.json',\n",
       " 'VAL_IMAGES_AFTER_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.hdf5',\n",
       " 'VAL_CAPLENS_blocks2D_logos_9_cap_per_img_pair_1_min_word_freq.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "datadir_pre = \"/data/blockworld_pre\"\n",
    "os.listdir(datadir_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os \n",
    "\n",
    "data_folder = \"/data/blockworld_pre\"\n",
    "base_filename = \"blocks2D_logos_9_cap_per_img_pair_1_min_word_freq\"\n",
    "split_name = \"TRAIN_IMAGES_AFTER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN IMAGES_BEFORE (667, 3, 360, 480)\n",
      "TRAIN IMAGES_AFTER (667, 3, 360, 480)\n",
      "VAL IMAGES_BEFORE (95, 3, 360, 480)\n",
      "VAL IMAGES_AFTER (95, 3, 360, 480)\n",
      "TEST IMAGES_BEFORE (181, 3, 360, 480)\n",
      "TEST IMAGES_AFTER (181, 3, 360, 480)\n"
     ]
    }
   ],
   "source": [
    "for split_name in [\"TRAIN\",\"VAL\",\"TEST\"]:\n",
    "    for image_type in [\"IMAGES_BEFORE\", \"IMAGES_AFTER\"]:\n",
    "        file_name = split_name + '_' + image_type + \"_\" + base_filename + '.hdf5'\n",
    "        with h5py.File(os.path.join(data_folder, file_name), 'r') as f:\n",
    "            samples = f[image_type.lower()]\n",
    "            print(split_name, image_type, samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def loadf(path):\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "def printl(j, pkeys=True, pmax=10):\n",
    "    if pkeys:\n",
    "        print(j.keys())\n",
    "    print(\"Keys: \", len(j.keys()))\n",
    "    sl = 0\n",
    "    for i, k in enumerate(j):\n",
    "        l = len(j[k])\n",
    "        if i < pmax:\n",
    "            print(k, l)\n",
    "        sl = sl + l\n",
    "    print(\"Total values: \" + str(sl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadcaps(split_name, base_filename, data_folder):\n",
    "    file_name = split_name + \"_CAPTIONS_\" + base_filename + \".json\"\n",
    "    return loadf(os.path.join(data_folder, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 6003\n",
      "VAL 855\n",
      "TEST 1629\n"
     ]
    }
   ],
   "source": [
    "for split_name in [\"TRAIN\",\"VAL\",\"TEST\"]:\n",
    "    caps = loadcaps(split_name, base_filename, data_folder)\n",
    "    print(split_name, len(caps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  39803\n",
      "CLEVR_default_026307.png 5\n",
      "CLEVR_default_018848.png 5\n",
      "CLEVR_default_003280.png 5\n",
      "CLEVR_default_001879.png 5\n",
      "CLEVR_default_021778.png 5\n",
      "CLEVR_default_022257.png 5\n",
      "CLEVR_default_021304.png 5\n",
      "CLEVR_default_013367.png 5\n",
      "CLEVR_default_016290.png 5\n",
      "CLEVR_default_029384.png 5\n",
      "Total values: 199015\n",
      "Min: 5 Max: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nsc = loadf(datadir + \"/no_change_captions.json\")\n",
    "printl(nsc, pkeys=False)\n",
    "print(\"Min:\",np.min([len(v) for v in nsc.values()]), \"Max:\", np.max([len(v) for v in nsc.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown',\n",
       " 'the tiny rubber cylinder became brown']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice, sample\n",
    "def samplecaps(imcaps, captions_per_image_pair=9):\n",
    "    # Sample captions\n",
    "    if len(imcaps) < captions_per_image_pair:\n",
    "        captions = imcaps + [choice(imcaps) for _ in range(captions_per_image_pair - len(imcaps))]\n",
    "    else:\n",
    "        captions = sample(imcaps, k=captions_per_image_pair)\n",
    "    return captions\n",
    "        \n",
    "samplecaps(sc[\"CLEVR_default_005422.png\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def showim(base_dir, split_dir, file_name):\n",
    "    path = os.path.join(base_dir, split_dir, file_name)\n",
    "    im = Image.open(path)\n",
    "    im = np.array(im).astype(\"uint8\")\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 1 Max: 9 Avg: 7.402157848063848 train 33830\n",
      "Min: 1 Max: 9 Avg: 7.369718309859155 val 1988\n",
      "Min: 1 Max: 9 Avg: 7.441405269761606 test 3985\n"
     ]
    }
   ],
   "source": [
    "# How many captions per split?\n",
    "import numpy as np\n",
    "def count_caps(splits, split_name):\n",
    "    lengths = []\n",
    "    for image_number in splits[split_name]:\n",
    "        ref = \"CLEVR_default_{:>06}.png\".format(image_number)\n",
    "        #print(ref, sc[ref]) \n",
    "        lengths.append(len(sc[ref]))\n",
    "    print(\"Min:\",np.min(lengths), \"Max:\", np.max(lengths), \"Avg:\", np.mean(lengths), split_name, len(lengths))\n",
    "count_caps(s, \"train\")\n",
    "count_caps(s, \"val\")\n",
    "count_caps(s, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 15, 7, 15, 17, 9, 7, 16, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35865"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpre = loadf(datadir_pre + \"/TEST_SC_CAPLENS_CLEVR_CHANGE_9_cap_per_img_pair_1_min_word_freq.json\")\n",
    "print(tpre[:10])\n",
    "len(tpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35865"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3985 * 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
