{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from dotted_dict import DottedDict\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils.dataset import CaptionDataset\n",
    "\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DottedDict()\n",
    "\n",
    "# model parameters\n",
    "# config.captions_per_image = 9 (never used)\n",
    "\n",
    "config.beam_size = 5\n",
    "config.nb_heads = 8  # number of attention heads on IMAGE used in the model -> important for figuring out visual word/sentence size\n",
    "\n",
    "config.data_folder = '/home/users/sadler/data/blockworld_pre'  # folder with data files saved by create_input_files.py\n",
    "config.data_name = 'blocks2D_logos_9_cap_per_img_pair_1_min_word_freq'  # base name shared by data files\n",
    "\n",
    "# Load word map (word2ix)\n",
    "word_map_file = os.path.join(config.data_folder, 'WORDMAP_' + config.data_name + '.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    config.word_map = json.load(j)\n",
    "config.rev_word_map = {v: k for k, v in config.word_map.items()}\n",
    "config.vocab_size = len(config.word_map)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # CPU isn't really practical here\n",
    "\n",
    "# Load model\n",
    "config.checkpoint_name = \"diff_att_8_MODEL_FINAL\"\n",
    "\n",
    "save_dir = \"/home/users/sadler/cache/052_block_instruct_transformer/models/blocks\"\n",
    "transformer_checkpoint = save_dir + \"/BEST_{}.pth.tar\".format(config.checkpoint_name)\n",
    "checkpoint = torch.load(transformer_checkpoint, map_location=torch.device('cuda'))\n",
    "\n",
    "model = checkpoint['model'].to(device)\n",
    "model.eval()\n",
    "image_feature_encoder = checkpoint['image_encoder'].to(device)\n",
    "image_feature_encoder.eval()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval_utils\n",
    "\n",
    "class Predictor():\n",
    "    \n",
    "    def __init__(self, context, model, image_encoder, device):\n",
    "        self.context = context\n",
    "        self.model = model\n",
    "        self.image_encoder = image_encoder\n",
    "        self.device = device\n",
    "        self.special_tokens = {context.word_map['<start>'],\n",
    "                              context.word_map['<end>'],\n",
    "                              context.word_map['<pad>']}\n",
    "\n",
    "    def predict(self, image_before, image_after):\n",
    "        best_hypothesis, _, _, _ = eval_utils.translate(\n",
    "                                                        self.context, \n",
    "                                                        self.model, \n",
    "                                                        self.image_encoder, \n",
    "                                                        self.device,\n",
    "                                                        image_before, image_after, \n",
    "                                                        length_norm_coefficient=0.6)\n",
    "        return [w for w in best_hypothesis if w not in self.special_tokens]\n",
    "    \n",
    "predictor = Predictor(config, model, image_feature_encoder, device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize as imresize\n",
    "from skimage.io import imread\n",
    "from skimage import color\n",
    "import numpy as np\n",
    "\n",
    "class Sampler():\n",
    "    \n",
    "    def __init__(self, data_folder, transform):\n",
    "        self.data_folder = data_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def get_image_by_name(self, name):\n",
    "        img_path = os.path.join(self.data_folder, name)\n",
    "        img_before = imread(img_path)\n",
    "        if img_before.shape[2] == 4:\n",
    "            img_before = color.rgba2rgb(img_before)\n",
    "        img_before = imresize(img_before, (360, 480))\n",
    "        assert img_before.shape == (360, 480, 3), \"But is {}\".format(img_before.shape)\n",
    "        img_before = img_before.transpose(2,0,1)\n",
    "        assert img_before.shape == (3, 360, 480), \"But is {}\".format(img_before.shape)\n",
    "        assert np.max(img_before) <= 255\n",
    "        return img_before\n",
    "\n",
    "    def get_image_pair_by_name(self, name_before, name_after):\n",
    "        img_before = self.get_image_by_name(name_before)\n",
    "        img_after = self.get_image_by_name(name_after)\n",
    "        img_before = torch.FloatTensor(img_before / 255.)\n",
    "        img_after = torch.FloatTensor(img_after / 255.)\n",
    "        return img_before, img_after\n",
    "\n",
    "    def get_sample_by_name(self, name_before, name_after):\n",
    "        img_before, img_after = self.get_image_pair_by_name(name_before, name_after)\n",
    "        if self.transform is not None:\n",
    "            img_before = self.transform(img_before)\n",
    "            img_after = self.transform(img_after)\n",
    "        return img_before, img_after\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some more logo image-pairs from the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testset.json', 'trainset.json', 'devset.json']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"/data/ImageCorpora/blockworld/MNIST/annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/data/ImageCorpora/blockworld/MNIST/annotations/testset.json\", \"r\") as f:\n",
    "    testdata = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['shape_params', 'decoration', 'notes', 'filename', 'states', 'images', 'side_length'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logodata = [d for d in testdata if d[\"decoration\"] == \"logo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatlogodata = [(n, d[\"images\"]) for idx, d in enumerate(logodata) for n in d[\"notes\"] if n[\"type\"] == \"A0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatlogodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(flatlogodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gts = flatlogodata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selection = [(random.choice(notes[\"notes\"]),images[notes[\"start\"]],images[notes[\"finish\"]]) for notes, images in gts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "sourcedir = \"/data/ImageCorpora/blockworld/MNIST/images/testset/\"\n",
    "targetdir = \"/data/blockworld_inspect/\"\n",
    "for s in selection:\n",
    "    copyfile(sourcedir + s[1], targetdir + s[1])\n",
    "    copyfile(sourcedir + s[2], targetdir + s[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: Slide the BMW vertically below the Adidas block.\n",
      "19_num1_06.png 19_num1_07.png\n",
      "\n",
      "gt: position the target block so that its aligned with the McDonald block and aligned with the center and top right of the Pepsi block.\n",
      "59_num5_01.png 59_num5_02.png\n",
      "\n",
      "gt: Move Burger King so it is below BMW\n",
      "99_num9_09.png 99_num9_10.png\n",
      "\n",
      "gt: Put the McDonalds block in the same row as the SRI block, horizontally equidistant between the SRI and Adidas blocks.\n",
      "48_num4_00.png 48_num4_01.png\n",
      "\n",
      "gt: Place the Nvidia block south of the Mercedes block.\n",
      "48_num4_16.png 48_num4_17.png\n",
      "\n",
      "gt: Move the Twitter block below the Toyota block\n",
      "68_num6_03.png 68_num6_04.png\n",
      "\n",
      "gt: Place the Burger King block in the first open space above the Coca Cola block.\n",
      "8_num0_17.png 8_num0_18.png\n",
      "\n",
      "gt: Place Twitter so its right edge is flush against the left edge of UPS.\n",
      "28_num2_01.png 28_num2_02.png\n",
      "\n",
      "gt: Move the Burger King block to the same vertical column as the Texaco block, and half a row above the McDonalds block.\n",
      "88_num8_00.png 88_num8_01.png\n",
      "\n",
      "gt: Take the Esso block and move it so it is diagonally above and to the right of the Adidas block.  The top right corner of the Adidas block should be touching the lower left corner of the Esso block.\n",
      "68_num6_14.png 68_num6_15.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in selection:\n",
    "    print(\"gt:\", s[0])\n",
    "    print(s[1], s[2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = Sampler(\"/data/ImageCorpora/blockworld/MNIST/images/trainset\", normalize)\n",
    "#name_before = \"73_num7_03.png\"\n",
    "#name_after = \"73_num7_04.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(\"/data/ImageCorpora/blockworld/MNIST/images/testset\", normalize)\n",
    "name_before = \"48_num4_05.png\"\n",
    "name_after = \"48_num4_06.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = []\n",
    "for gt, b, a in selection:\n",
    "    bi, ai = sampler.get_sample_by_name(b,a)\n",
    "    hyp = predictor.predict(bi.unsqueeze(dim=0), ai.unsqueeze(dim=0))\n",
    "    hyps.append(hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19_num1_06.png 19_num1_07.png\n",
      "slide the bmw vertically below the adidas block.\n",
      "move the bmw block below the adidas block.\n",
      "\n",
      "59_num5_01.png 59_num5_02.png\n",
      "position the target block so that its aligned with the mcdonald block and aligned with the center and top right of the pepsi block.\n",
      "move the target block to the left of the twitter block.\n",
      "\n",
      "99_num9_09.png 99_num9_10.png\n",
      "move burger king so it is below bmw\n",
      "move the burger king block below the bmw block.\n",
      "\n",
      "48_num4_00.png 48_num4_01.png\n",
      "put the mcdonalds block in the same row as the sri block, horizontally equidistant between the sri and adidas blocks.\n",
      "put the mcdonalds block in the first open space to the right of the bmw block.\n",
      "\n",
      "48_num4_16.png 48_num4_17.png\n",
      "place the nvidia block south of the mercedes block.\n",
      "move the nvidia block below the mercedes block.\n",
      "\n",
      "68_num6_03.png 68_num6_04.png\n",
      "move the twitter block below the toyota block\n",
      "move the twitter block below the toyota block.\n",
      "\n",
      "8_num0_17.png 8_num0_18.png\n",
      "place the burger king block in the first open space above the coca cola block.\n",
      "move the burger king block above the coca cola block.\n",
      "\n",
      "28_num2_01.png 28_num2_02.png\n",
      "place twitter so its right edge is flush against the left edge of ups.\n",
      "move the twitter block to the left of the ups block.\n",
      "\n",
      "88_num8_00.png 88_num8_01.png\n",
      "move the burger king block to the same vertical column as the texaco block, and half a row above the mcdonalds block.\n",
      "move the burger king block above and to the right of the bmw block.\n",
      "\n",
      "68_num6_14.png 68_num6_15.png\n",
      "take the esso block and move it so it is diagonally above and to the right of the adidas block.  the top right corner of the adidas block should be touching the lower left corner of the esso block.\n",
      "place the esso block northeast of the bmw block.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (gt,a,b),hyp in zip(selection, hyps):\n",
    "    print(a,b)\n",
    "    print(gt.lower())\n",
    "    print(\" \".join(hyp))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "msampler = Sampler(\"/data/blockworld_inspect/masked\", normalize)\n",
    "mhyps = []\n",
    "for gt, b, a in selection:\n",
    "    bi, ai = msampler.get_sample_by_name(b,a)\n",
    "    hyp = predictor.predict(bi.unsqueeze(dim=0), ai.unsqueeze(dim=0))\n",
    "    mhyps.append(hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19_num1_06.png 19_num1_07.png\n",
      "['move', 'the', 'bmw', 'block', 'below', 'the', 'adidas', 'block.']\n",
      "['move', 'the', 'nvidia', 'block', 'below', 'and', 'to', 'the', 'left', 'of', 'the', 'sri', 'block.']\n",
      "\n",
      "59_num5_01.png 59_num5_02.png\n",
      "['move', 'the', 'target', 'block', 'to', 'the', 'left', 'of', 'the', 'twitter', 'block.']\n",
      "['move', 'the', 'target', 'block', 'to', 'the', 'left', 'of', 'the', 'sri', 'block.']\n",
      "\n",
      "99_num9_09.png 99_num9_10.png\n",
      "['move', 'the', 'burger', 'king', 'block', 'below', 'the', 'bmw', 'block.']\n",
      "['move', 'the', 'burger', 'king', 'block', 'to', 'the', 'left', 'of', 'the', 'sri', 'block.']\n",
      "\n",
      "48_num4_00.png 48_num4_01.png\n",
      "['put', 'the', 'mcdonalds', 'block', 'in', 'the', 'first', 'open', 'space', 'to', 'the', 'right', 'of', 'the', 'bmw', 'block.']\n",
      "['put', 'the', 'mcdonalds', 'block', 'in', 'the', 'first', 'open', 'space', 'to', 'the', 'right', 'of', 'the', 'bmw', 'block.']\n",
      "\n",
      "48_num4_16.png 48_num4_17.png\n",
      "['move', 'the', 'nvidia', 'block', 'below', 'the', 'mercedes', 'block.']\n",
      "['move', 'the', 'nvidia', 'block', 'below', 'and', 'to', 'the', 'left', 'of', 'the', 'sri', 'block.']\n",
      "\n",
      "68_num6_03.png 68_num6_04.png\n",
      "['move', 'the', 'twitter', 'block', 'below', 'the', 'toyota', 'block.']\n",
      "['move', 'the', 'twitter', 'block', 'below', 'and', 'to', 'the', 'left', 'of', 'the', 'sri', 'block.']\n",
      "\n",
      "8_num0_17.png 8_num0_18.png\n",
      "['move', 'the', 'burger', 'king', 'block', 'above', 'the', 'coca', 'cola', 'block.']\n",
      "['move', 'the', 'burger', 'king', 'block', 'above', 'the', 'coca', 'cola', 'block.']\n",
      "\n",
      "28_num2_01.png 28_num2_02.png\n",
      "['move', 'the', 'twitter', 'block', 'to', 'the', 'left', 'of', 'the', 'ups', 'block.']\n",
      "['move', 'the', 'twitter', 'block', 'to', 'the', 'left', 'of', 'the', 'ups', 'block.']\n",
      "\n",
      "88_num8_00.png 88_num8_01.png\n",
      "['move', 'the', 'burger', 'king', 'block', 'above', 'and', 'to', 'the', 'right', 'of', 'the', 'bmw', 'block.']\n",
      "['move', 'the', 'burger', 'king', 'block', 'above', 'and', 'to', 'the', 'right', 'of', 'the', 'bmw', 'block.']\n",
      "\n",
      "68_num6_14.png 68_num6_15.png\n",
      "['place', 'the', 'esso', 'block', 'northeast', 'of', 'the', 'bmw', 'block.']\n",
      "['put', 'the', 'esso', 'block', 'in', 'the', 'first', 'open', 'space', 'northeast', 'of', 'the', 'sri', 'block.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (gt, b, a), hyp, mhyp in zip(selection, hyps, mhyps):\n",
    "    print(b,a)\n",
    "    print(hyp)\n",
    "    print(mhyp)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
